{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def setup_datasets(self):\n",
    "        # tf.enable_eager_execution()\n",
    "\n",
    "        # generate indices for each dataset\n",
    "        # also write cluster info\n",
    "\n",
    "        CIFAR10_TRAINSET_DATA_SIZE = 50000\n",
    "        CIFAR10_TESTSET_DATA_SIZE = 10000\n",
    "\n",
    "        cfg = self.config\n",
    "\n",
    "        self.dataset = {}\n",
    "\n",
    "        dataset = {}\n",
    "        dataset['data_indices'], dataset['cluster_assign'] = \\\n",
    "            self._setup_dataset(CIFAR10_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
    "        dl = self._load_CIFAR(train=True)\n",
    "        dataset['data_loader'] = dl\n",
    "        self.dataset['train'] = dataset\n",
    "\n",
    "        dataset = {}\n",
    "        dataset['data_indices'], dataset['cluster_assign'] = \\\n",
    "            self._setup_dataset(CIFAR10_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'], random=False)\n",
    "        dl = self._load_CIFAR(train=False)\n",
    "        dataset['data_loader'] = dl\n",
    "        self.dataset['test'] = dataset\n",
    "\n",
    "        # tf.disable_eager_execution()\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "\n",
    "def _setup_dataset(num_data, p, m, n, random = True):\n",
    "\n",
    "        assert (m // p) * n == num_data\n",
    "\n",
    "        dataset = {}\n",
    "\n",
    "        data_indices = []\n",
    "        cluster_assign = []\n",
    "\n",
    "        m_per_cluster = m // p\n",
    "\n",
    "        for p_i in range(p):\n",
    "\n",
    "            if random:\n",
    "                ll = list(np.random.permutation(num_data))\n",
    "            else:\n",
    "                ll = list(range(num_data))\n",
    "\n",
    "            ll2 = chunkify(ll, m_per_cluster) # splits ll into m lists with size n\n",
    "            data_indices += ll2\n",
    "\n",
    "            cluster_assign += [p_i for _ in range(m_per_cluster)]\n",
    "\n",
    "        data_indices = np.array(data_indices)\n",
    "        cluster_assign = np.array(cluster_assign)\n",
    "        assert data_indices.shape[0] == cluster_assign.shape[0]\n",
    "        assert data_indices.shape[0] == m\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        return data_indices, cluster_assign\n",
    "\n",
    "\n",
    "def load_CIFAR(train=True):\n",
    "        # gives dataloader that gives (X,y) based on asked index\n",
    "\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "        # (50000, 32,32, 3) [0~1] , (50000, 1)\n",
    "\n",
    "        if train:\n",
    "            X = x_train / 255.0\n",
    "            y = y_train.reshape(-1)\n",
    "        else:\n",
    "            X = x_test / 255.0\n",
    "            y = y_test.reshape(-1)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "def chunk(a, i, n):\n",
    "    a2 = chunkify(a, n)\n",
    "    return a2[i]\n",
    "\n",
    "def chunkify(a, n):\n",
    "    # splits list into even size list of lists\n",
    "    # [1,2,3,4] -> [1,2], [3,4]\n",
    "\n",
    "    k, m = divmod(len(a), n)\n",
    "    gen = (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "    return list(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_CIFAR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "\n",
    "def get_config():\n",
    "    arg_seed = 0\n",
    "\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--project-dir\",type=str,default=\"output\")\n",
    "    # parser.add_argument(\"--dataset-dir\",type=str,default=\"output\")\n",
    "    # # parser.add_argument(\"--num-epochs\",type=float,default=)\n",
    "    # # parser.add_argument(\"--lr\",type=float,default=0.2)\n",
    "    # parser.add_argument(\"--data-seed\",type=int,default=0)\n",
    "    # parser.add_argument(\"--train-seed\",type=int,default=arg_seed)\n",
    "    # parser.add_argument(\"--config-override\",type=str,default=\"\")\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    args = {}\n",
    "    args['project_dir'] = \"output\"\n",
    "    args['dataset_dir'] = \"output\"\n",
    "    args['data_seed'] = 0\n",
    "    args['train_seed'] = arg_seed\n",
    "    args['config_override'] = \"\"\n",
    "\n",
    "    # read config json and update the sysarg\n",
    "    with open(\"config.json\", \"r\") as read_file:\n",
    "        config = json.load(read_file)\n",
    "\n",
    "    #args_dict = vars(args)\n",
    "    config.update(args)\n",
    "\n",
    "    if config[\"config_override\"] == \"\":\n",
    "        del config['config_override']\n",
    "    else:\n",
    "        print(config['config_override'])\n",
    "        config_override = json.loads(config['config_override'])\n",
    "        del config['config_override']\n",
    "        config.update(config_override)\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "\n",
    "CIFAR10_TRAINSET_DATA_SIZE = 50000\n",
    "CIFAR10_TESTSET_DATA_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m': 200,\n",
       " 'm_test': 40,\n",
       " 'p': 2,\n",
       " 'n': 500,\n",
       " 'participation_rate': 0.1,\n",
       " 'num_epochs': 600,\n",
       " 'batch_size': 50,\n",
       " 'tau': 5,\n",
       " 'lr': 0.25,\n",
       " 'data_seed': 0,\n",
       " 'train_seed': 0,\n",
       " 'project_dir': 'output',\n",
       " 'dataset_dir': 'output'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "        dataset = {}\n",
    "        dataset['data_indices'], dataset['cluster_assign'] = \\\n",
    "            _setup_dataset(CIFAR10_TRAINSET_DATA_SIZE, config['p'], config['m'], config['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['data_indices'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4531, 16706, 27330, 45634,  3969, 23281,   925, 13811, 24489,\n",
       "       21235, 40628, 47354, 25310, 34723, 15920, 16664, 46934, 12044,\n",
       "         479, 31794, 43418, 10162, 32400,  9410, 10657, 46177, 44512,\n",
       "       49798, 16810, 38988, 20447,  5563, 18463,  9631, 31905, 28649,\n",
       "       17721, 36098, 17131, 42712, 11474, 46045, 11839, 22687, 32219,\n",
       "       14864, 45612, 13822,   707, 28901, 23144, 38082, 12471,  2641,\n",
       "       27579,  5651, 33262, 30004, 23568, 35909,  5656, 47076, 25525,\n",
       "       31644, 23992, 46038, 36681, 26721, 37063, 18355, 24793,  4288,\n",
       "       47194, 18267, 21883, 36840, 41256, 25606, 37857, 37807, 20012,\n",
       "       34750, 13066, 11748, 31937, 43239, 38127, 19901,  1735, 48098,\n",
       "       30745, 37159,   970, 16389,  2793, 42037,  6886,  5774, 29366,\n",
       "       40854, 19785, 49763, 45042,  5856, 36976, 10138, 32313, 32968,\n",
       "        5989, 46660, 21649, 27723, 32513, 17219, 41421,  7540, 39779,\n",
       "        3847, 40242, 47809, 10809,  5042, 36472, 26282, 28817,   558,\n",
       "       48781,  5708, 33673, 15987, 20807,  7775,  5918, 33975, 18496,\n",
       "       28768, 14506, 23566,   857, 12770, 28303, 48385,  5887, 11404,\n",
       "        8079, 31471, 34643, 10299, 22553, 10805, 20902, 43721,  3833,\n",
       "       33385, 21188,  7995, 32603, 14138, 45666, 43248, 24817,  3155,\n",
       "       39026, 47053,  9245,   507, 38478, 18635, 36650, 36534, 13134,\n",
       "       40026, 26845, 18215,   668, 22577, 26134, 28754,  9396,  3173,\n",
       "       23173, 42815,  4347,  9777, 32525, 28914,  7141, 14406, 21513,\n",
       "       26733, 15738, 34573,  2873, 41602, 35287, 17561, 17692, 42783,\n",
       "       43005, 37360, 23413, 26025,  1017, 19628, 22407,  4872,  8888,\n",
       "       22464, 44352, 44974, 48470, 36783, 35061, 14190, 44355,  8567,\n",
       "       28125, 20256, 14774, 17203, 11822, 45530, 35977,   427,  3337,\n",
       "         419, 40699, 32876, 33183, 16368,   428, 21249, 35168, 27387,\n",
       "         379, 43206, 49396, 36345,  9588, 34936,    69,  9509, 24944,\n",
       "        5784, 13042, 40265, 19669, 29195, 16324, 21078, 40667, 21280,\n",
       "       37252, 28066, 38894, 42060, 10360,   965, 17388, 48507, 19789,\n",
       "       18255, 19251, 28664, 11569, 41697,  2419,  4791, 40812,  3457,\n",
       "       34058, 37586, 28823, 13169, 40891, 41752, 40889, 18010,  9839,\n",
       "        5331, 30060, 39849,  2387, 12865, 11627,  1137, 25097, 47935,\n",
       "       44057, 16962, 31850, 26629, 29869, 25341,  9190, 18426, 47548,\n",
       "       10680, 49850, 35017, 46229, 20732, 48204, 12687, 25356, 41860,\n",
       "       31735, 48914, 40602, 38221, 14092, 44990, 32106, 36475, 39052,\n",
       "       46208, 47484, 47176, 29825, 30876, 47240,  2966,  6183, 49468,\n",
       "       11022,  8533, 18483, 23007, 25825, 25734, 24296, 26145,  2510,\n",
       "        9145,   988, 49855, 36077, 31223, 42169, 37814, 39940,  4975,\n",
       "       17352,  8186, 13320, 20636, 38191,  7322, 46972, 32930, 39099,\n",
       "       17333, 39635, 32940,  8698, 30333,  2107, 10286, 13571, 41570,\n",
       "       25373,  6500,   481, 37791, 14146, 26783, 30854,  5624, 10423,\n",
       "        7866, 35357, 42612, 22904, 39911, 16151, 48588, 44272, 29796,\n",
       "       47043, 27081,  5125,  8190, 14546, 37753, 20143, 30531, 26455,\n",
       "        2694,  9010, 32159, 25929, 19290, 45915, 46681, 25981,  8113,\n",
       "         605, 34301,  3928, 24039, 34863, 42263, 29513, 10012, 41332,\n",
       "       26590,  5601, 48844, 32432,  2544, 27208, 38023,  8470, 42636,\n",
       "       12666, 40427, 29953, 14402, 26673, 29840, 36029, 34862, 21503,\n",
       "        8350, 36352,  4717, 36479, 10079,  1281, 24796, 36190,  5617,\n",
       "       35722, 49435,  3420, 40429,  2982, 17566, 26843, 26419, 24114,\n",
       "        2048, 41699,  7018,  7910, 42196, 25055, 24524,  2064, 10645,\n",
       "       47933, 16355, 23980, 21788, 28384, 13843, 13000,  6456, 27879,\n",
       "       10092, 43788,  5873, 40363, 18741,  5863,  7465, 17950, 14456,\n",
       "        6541, 19122, 43525, 46382, 20006, 40419, 37592, 42155, 32042,\n",
       "        8371, 33687, 12786,  3856, 37220, 30739, 29977, 45865, 38750,\n",
       "       45103, 49076, 32823, 26394, 20017,  7741, 42383, 49417, 48684,\n",
       "       23569,  1355, 48937, 15015, 41175])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['data_indices'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['cluster_assign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataset['cluster_assign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = load_CIFAR(train=True)\n",
    "dataset['data_loader'] = dl\n",
    "dataset['train'] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_indices': array([[ 4531, 16706, 27330, ..., 48937, 15015, 41175],\n",
       "        [35258, 41521, 11652, ..., 46226,  7814, 17660],\n",
       "        [47526, 48773,  6957, ..., 27321,  8132, 20080],\n",
       "        ...,\n",
       "        [43729, 33505, 18858, ..., 30152, 30086, 15568],\n",
       "        [25025, 15652,  8449, ..., 49920, 44358,  6505],\n",
       "        [30240, 49466, 39136, ..., 47356, 37741, 37371]]),\n",
       " 'cluster_assign': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1]),\n",
       " 'data_loader': (array([[[[0.23137255, 0.24313725, 0.24705882],\n",
       "           [0.16862745, 0.18039216, 0.17647059],\n",
       "           [0.19607843, 0.18823529, 0.16862745],\n",
       "           ...,\n",
       "           [0.61960784, 0.51764706, 0.42352941],\n",
       "           [0.59607843, 0.49019608, 0.4       ],\n",
       "           [0.58039216, 0.48627451, 0.40392157]],\n",
       "  \n",
       "          [[0.0627451 , 0.07843137, 0.07843137],\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.07058824, 0.03137255, 0.        ],\n",
       "           ...,\n",
       "           [0.48235294, 0.34509804, 0.21568627],\n",
       "           [0.46666667, 0.3254902 , 0.19607843],\n",
       "           [0.47843137, 0.34117647, 0.22352941]],\n",
       "  \n",
       "          [[0.09803922, 0.09411765, 0.08235294],\n",
       "           [0.0627451 , 0.02745098, 0.        ],\n",
       "           [0.19215686, 0.10588235, 0.03137255],\n",
       "           ...,\n",
       "           [0.4627451 , 0.32941176, 0.19607843],\n",
       "           [0.47058824, 0.32941176, 0.19607843],\n",
       "           [0.42745098, 0.28627451, 0.16470588]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.81568627, 0.66666667, 0.37647059],\n",
       "           [0.78823529, 0.6       , 0.13333333],\n",
       "           [0.77647059, 0.63137255, 0.10196078],\n",
       "           ...,\n",
       "           [0.62745098, 0.52156863, 0.2745098 ],\n",
       "           [0.21960784, 0.12156863, 0.02745098],\n",
       "           [0.20784314, 0.13333333, 0.07843137]],\n",
       "  \n",
       "          [[0.70588235, 0.54509804, 0.37647059],\n",
       "           [0.67843137, 0.48235294, 0.16470588],\n",
       "           [0.72941176, 0.56470588, 0.11764706],\n",
       "           ...,\n",
       "           [0.72156863, 0.58039216, 0.36862745],\n",
       "           [0.38039216, 0.24313725, 0.13333333],\n",
       "           [0.3254902 , 0.20784314, 0.13333333]],\n",
       "  \n",
       "          [[0.69411765, 0.56470588, 0.45490196],\n",
       "           [0.65882353, 0.50588235, 0.36862745],\n",
       "           [0.70196078, 0.55686275, 0.34117647],\n",
       "           ...,\n",
       "           [0.84705882, 0.72156863, 0.54901961],\n",
       "           [0.59215686, 0.4627451 , 0.32941176],\n",
       "           [0.48235294, 0.36078431, 0.28235294]]],\n",
       "  \n",
       "  \n",
       "         [[[0.60392157, 0.69411765, 0.73333333],\n",
       "           [0.49411765, 0.5372549 , 0.53333333],\n",
       "           [0.41176471, 0.40784314, 0.37254902],\n",
       "           ...,\n",
       "           [0.35686275, 0.37254902, 0.27843137],\n",
       "           [0.34117647, 0.35294118, 0.27843137],\n",
       "           [0.30980392, 0.31764706, 0.2745098 ]],\n",
       "  \n",
       "          [[0.54901961, 0.62745098, 0.6627451 ],\n",
       "           [0.56862745, 0.6       , 0.60392157],\n",
       "           [0.49019608, 0.49019608, 0.4627451 ],\n",
       "           ...,\n",
       "           [0.37647059, 0.38823529, 0.30588235],\n",
       "           [0.30196078, 0.31372549, 0.24313725],\n",
       "           [0.27843137, 0.28627451, 0.23921569]],\n",
       "  \n",
       "          [[0.54901961, 0.60784314, 0.64313725],\n",
       "           [0.54509804, 0.57254902, 0.58431373],\n",
       "           [0.45098039, 0.45098039, 0.43921569],\n",
       "           ...,\n",
       "           [0.30980392, 0.32156863, 0.25098039],\n",
       "           [0.26666667, 0.2745098 , 0.21568627],\n",
       "           [0.2627451 , 0.27058824, 0.21568627]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.68627451, 0.65490196, 0.65098039],\n",
       "           [0.61176471, 0.60392157, 0.62745098],\n",
       "           [0.60392157, 0.62745098, 0.66666667],\n",
       "           ...,\n",
       "           [0.16470588, 0.13333333, 0.14117647],\n",
       "           [0.23921569, 0.20784314, 0.22352941],\n",
       "           [0.36470588, 0.3254902 , 0.35686275]],\n",
       "  \n",
       "          [[0.64705882, 0.60392157, 0.50196078],\n",
       "           [0.61176471, 0.59607843, 0.50980392],\n",
       "           [0.62352941, 0.63137255, 0.55686275],\n",
       "           ...,\n",
       "           [0.40392157, 0.36470588, 0.37647059],\n",
       "           [0.48235294, 0.44705882, 0.47058824],\n",
       "           [0.51372549, 0.4745098 , 0.51372549]],\n",
       "  \n",
       "          [[0.63921569, 0.58039216, 0.47058824],\n",
       "           [0.61960784, 0.58039216, 0.47843137],\n",
       "           [0.63921569, 0.61176471, 0.52156863],\n",
       "           ...,\n",
       "           [0.56078431, 0.52156863, 0.54509804],\n",
       "           [0.56078431, 0.5254902 , 0.55686275],\n",
       "           [0.56078431, 0.52156863, 0.56470588]]],\n",
       "  \n",
       "  \n",
       "         [[[1.        , 1.        , 1.        ],\n",
       "           [0.99215686, 0.99215686, 0.99215686],\n",
       "           [0.99215686, 0.99215686, 0.99215686],\n",
       "           ...,\n",
       "           [0.99215686, 0.99215686, 0.99215686],\n",
       "           [0.99215686, 0.99215686, 0.99215686],\n",
       "           [0.99215686, 0.99215686, 0.99215686]],\n",
       "  \n",
       "          [[1.        , 1.        , 1.        ],\n",
       "           [1.        , 1.        , 1.        ],\n",
       "           [1.        , 1.        , 1.        ],\n",
       "           ...,\n",
       "           [1.        , 1.        , 1.        ],\n",
       "           [1.        , 1.        , 1.        ],\n",
       "           [1.        , 1.        , 1.        ]],\n",
       "  \n",
       "          [[1.        , 1.        , 1.        ],\n",
       "           [0.99607843, 0.99607843, 0.99607843],\n",
       "           [0.99607843, 0.99607843, 0.99607843],\n",
       "           ...,\n",
       "           [0.99607843, 0.99607843, 0.99607843],\n",
       "           [0.99607843, 0.99607843, 0.99607843],\n",
       "           [0.99607843, 0.99607843, 0.99607843]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.44313725, 0.47058824, 0.43921569],\n",
       "           [0.43529412, 0.4627451 , 0.43529412],\n",
       "           [0.41176471, 0.43921569, 0.41568627],\n",
       "           ...,\n",
       "           [0.28235294, 0.31764706, 0.31372549],\n",
       "           [0.28235294, 0.31372549, 0.30980392],\n",
       "           [0.28235294, 0.31372549, 0.30980392]],\n",
       "  \n",
       "          [[0.43529412, 0.4627451 , 0.43137255],\n",
       "           [0.40784314, 0.43529412, 0.40784314],\n",
       "           [0.38823529, 0.41568627, 0.38431373],\n",
       "           ...,\n",
       "           [0.26666667, 0.29411765, 0.28627451],\n",
       "           [0.2745098 , 0.29803922, 0.29411765],\n",
       "           [0.30588235, 0.32941176, 0.32156863]],\n",
       "  \n",
       "          [[0.41568627, 0.44313725, 0.41176471],\n",
       "           [0.38823529, 0.41568627, 0.38431373],\n",
       "           [0.37254902, 0.4       , 0.36862745],\n",
       "           ...,\n",
       "           [0.30588235, 0.33333333, 0.3254902 ],\n",
       "           [0.30980392, 0.33333333, 0.3254902 ],\n",
       "           [0.31372549, 0.3372549 , 0.32941176]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[0.1372549 , 0.69803922, 0.92156863],\n",
       "           [0.15686275, 0.69019608, 0.9372549 ],\n",
       "           [0.16470588, 0.69019608, 0.94509804],\n",
       "           ...,\n",
       "           [0.38823529, 0.69411765, 0.85882353],\n",
       "           [0.30980392, 0.57647059, 0.77254902],\n",
       "           [0.34901961, 0.58039216, 0.74117647]],\n",
       "  \n",
       "          [[0.22352941, 0.71372549, 0.91764706],\n",
       "           [0.17254902, 0.72156863, 0.98039216],\n",
       "           [0.19607843, 0.71764706, 0.94117647],\n",
       "           ...,\n",
       "           [0.61176471, 0.71372549, 0.78431373],\n",
       "           [0.55294118, 0.69411765, 0.80784314],\n",
       "           [0.45490196, 0.58431373, 0.68627451]],\n",
       "  \n",
       "          [[0.38431373, 0.77254902, 0.92941176],\n",
       "           [0.25098039, 0.74117647, 0.98823529],\n",
       "           [0.27058824, 0.75294118, 0.96078431],\n",
       "           ...,\n",
       "           [0.7372549 , 0.76470588, 0.80784314],\n",
       "           [0.46666667, 0.52941176, 0.57647059],\n",
       "           [0.23921569, 0.30980392, 0.35294118]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.28627451, 0.30980392, 0.30196078],\n",
       "           [0.20784314, 0.24705882, 0.26666667],\n",
       "           [0.21176471, 0.26666667, 0.31372549],\n",
       "           ...,\n",
       "           [0.06666667, 0.15686275, 0.25098039],\n",
       "           [0.08235294, 0.14117647, 0.2       ],\n",
       "           [0.12941176, 0.18823529, 0.19215686]],\n",
       "  \n",
       "          [[0.23921569, 0.26666667, 0.29411765],\n",
       "           [0.21568627, 0.2745098 , 0.3372549 ],\n",
       "           [0.22352941, 0.30980392, 0.40392157],\n",
       "           ...,\n",
       "           [0.09411765, 0.18823529, 0.28235294],\n",
       "           [0.06666667, 0.1372549 , 0.20784314],\n",
       "           [0.02745098, 0.09019608, 0.1254902 ]],\n",
       "  \n",
       "          [[0.17254902, 0.21960784, 0.28627451],\n",
       "           [0.18039216, 0.25882353, 0.34509804],\n",
       "           [0.19215686, 0.30196078, 0.41176471],\n",
       "           ...,\n",
       "           [0.10588235, 0.20392157, 0.30196078],\n",
       "           [0.08235294, 0.16862745, 0.25882353],\n",
       "           [0.04705882, 0.12156863, 0.19607843]]],\n",
       "  \n",
       "  \n",
       "         [[[0.74117647, 0.82745098, 0.94117647],\n",
       "           [0.72941176, 0.81568627, 0.9254902 ],\n",
       "           [0.7254902 , 0.81176471, 0.92156863],\n",
       "           ...,\n",
       "           [0.68627451, 0.76470588, 0.87843137],\n",
       "           [0.6745098 , 0.76078431, 0.87058824],\n",
       "           [0.6627451 , 0.76078431, 0.8627451 ]],\n",
       "  \n",
       "          [[0.76078431, 0.82352941, 0.9372549 ],\n",
       "           [0.74901961, 0.81176471, 0.9254902 ],\n",
       "           [0.74509804, 0.80784314, 0.92156863],\n",
       "           ...,\n",
       "           [0.67843137, 0.75294118, 0.8627451 ],\n",
       "           [0.67058824, 0.74901961, 0.85490196],\n",
       "           [0.65490196, 0.74509804, 0.84705882]],\n",
       "  \n",
       "          [[0.81568627, 0.85882353, 0.95686275],\n",
       "           [0.80392157, 0.84705882, 0.94117647],\n",
       "           [0.8       , 0.84313725, 0.9372549 ],\n",
       "           ...,\n",
       "           [0.68627451, 0.74901961, 0.85098039],\n",
       "           [0.6745098 , 0.74509804, 0.84705882],\n",
       "           [0.6627451 , 0.74901961, 0.84313725]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.81176471, 0.78039216, 0.70980392],\n",
       "           [0.79607843, 0.76470588, 0.68627451],\n",
       "           [0.79607843, 0.76862745, 0.67843137],\n",
       "           ...,\n",
       "           [0.52941176, 0.51764706, 0.49803922],\n",
       "           [0.63529412, 0.61960784, 0.58823529],\n",
       "           [0.65882353, 0.63921569, 0.59215686]],\n",
       "  \n",
       "          [[0.77647059, 0.74509804, 0.66666667],\n",
       "           [0.74117647, 0.70980392, 0.62352941],\n",
       "           [0.70588235, 0.6745098 , 0.57647059],\n",
       "           ...,\n",
       "           [0.69803922, 0.67058824, 0.62745098],\n",
       "           [0.68627451, 0.6627451 , 0.61176471],\n",
       "           [0.68627451, 0.6627451 , 0.60392157]],\n",
       "  \n",
       "          [[0.77647059, 0.74117647, 0.67843137],\n",
       "           [0.74117647, 0.70980392, 0.63529412],\n",
       "           [0.69803922, 0.66666667, 0.58431373],\n",
       "           ...,\n",
       "           [0.76470588, 0.72156863, 0.6627451 ],\n",
       "           [0.76862745, 0.74117647, 0.67058824],\n",
       "           [0.76470588, 0.74509804, 0.67058824]]],\n",
       "  \n",
       "  \n",
       "         [[[0.89803922, 0.89803922, 0.9372549 ],\n",
       "           [0.9254902 , 0.92941176, 0.96862745],\n",
       "           [0.91764706, 0.9254902 , 0.96862745],\n",
       "           ...,\n",
       "           [0.85098039, 0.85882353, 0.91372549],\n",
       "           [0.86666667, 0.8745098 , 0.91764706],\n",
       "           [0.87058824, 0.8745098 , 0.91372549]],\n",
       "  \n",
       "          [[0.87058824, 0.86666667, 0.89803922],\n",
       "           [0.9372549 , 0.9372549 , 0.97647059],\n",
       "           [0.91372549, 0.91764706, 0.96470588],\n",
       "           ...,\n",
       "           [0.8745098 , 0.8745098 , 0.9254902 ],\n",
       "           [0.89019608, 0.89411765, 0.93333333],\n",
       "           [0.82352941, 0.82745098, 0.8627451 ]],\n",
       "  \n",
       "          [[0.83529412, 0.80784314, 0.82745098],\n",
       "           [0.91764706, 0.90980392, 0.9372549 ],\n",
       "           [0.90588235, 0.91372549, 0.95686275],\n",
       "           ...,\n",
       "           [0.8627451 , 0.8627451 , 0.90980392],\n",
       "           [0.8627451 , 0.85882353, 0.90980392],\n",
       "           [0.79215686, 0.79607843, 0.84313725]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.58823529, 0.56078431, 0.52941176],\n",
       "           [0.54901961, 0.52941176, 0.49803922],\n",
       "           [0.51764706, 0.49803922, 0.47058824],\n",
       "           ...,\n",
       "           [0.87843137, 0.87058824, 0.85490196],\n",
       "           [0.90196078, 0.89411765, 0.88235294],\n",
       "           [0.94509804, 0.94509804, 0.93333333]],\n",
       "  \n",
       "          [[0.5372549 , 0.51764706, 0.49411765],\n",
       "           [0.50980392, 0.49803922, 0.47058824],\n",
       "           [0.49019608, 0.4745098 , 0.45098039],\n",
       "           ...,\n",
       "           [0.70980392, 0.70588235, 0.69803922],\n",
       "           [0.79215686, 0.78823529, 0.77647059],\n",
       "           [0.83137255, 0.82745098, 0.81176471]],\n",
       "  \n",
       "          [[0.47843137, 0.46666667, 0.44705882],\n",
       "           [0.4627451 , 0.45490196, 0.43137255],\n",
       "           [0.47058824, 0.45490196, 0.43529412],\n",
       "           ...,\n",
       "           [0.70196078, 0.69411765, 0.67843137],\n",
       "           [0.64313725, 0.64313725, 0.63529412],\n",
       "           [0.63921569, 0.63921569, 0.63137255]]]]),\n",
       "  array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)),\n",
       " 'train': {...}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['cluster_assign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['data_indices'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x760ff8316950>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show image in color\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = dataset['data_loader'][0][dataset['data_indices'][0]][3]\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 // 2) * 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(200 // 2) * 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import non_iiddata_generator_no_drifting as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcBklEQVR4nO3df3DU9Z3H8dfyIwtisjGE/CqBBlToCaRXhJhT8QcZIJ1jRJk58ccNOJ4ONHgFtCg9FdH20uKNOirKPz2iN6KWO4HRTmk1mDC0gQ4Ih0w1R5goOJBQcdgNQRaGfO4PdHUhQT7Lbt7J8nzMfGeyu99X9u3XL/viy/ebbwLOOScAALpZH+sBAAAXJwoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJvpZD3Cmjo4OHThwQJmZmQoEAtbjAAA8OefU1tamoqIi9enT9XFOjyugAwcOqLi42HoMAMAF2r9/v4YOHdrl6z2ugDIzM7/6ar+kLMtRAAAJiUgq/tbneedSVkArVqzQ008/rZaWFpWWluqFF17QxIkTvzP3zT+7ZYkCAoDe67tOo6TkIoQ333xTixYt0tKlS/XBBx+otLRUU6dO1aFDh1LxdgCAXiiQirthl5WVacKECXrxxRclnb6woLi4WA888IAeeeSRc2YjkYhCoZCksDgCAoDeKCIppHA4rKysrj/Hk34EdOLECW3fvl0VFRXfvEmfPqqoqFBDQ8NZ60ejUUUikbgFAJD+kl5An3/+uU6dOqX8/Py45/Pz89XS0nLW+tXV1QqFQrGFK+AA4OJg/oOoS5YsUTgcji379++3HgkA0A2SfhVcbm6u+vbtq9bW1rjnW1tbVVBQcNb6wWBQwWAw2WMAAHq4pB8BZWRkaPz48aqtrY0919HRodraWpWXlyf77QAAvVRKfg5o0aJFmj17tq6++mpNnDhRzz33nNrb23XPPfek4u0AAL1QSgro9ttv19/+9jc9/vjjamlp0Q9/+ENt2LDhrAsTAAAXr5T8HNCF4OeAAKC3M/o5IAAAzgcFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAEz0sx4A6O1Gj/bPfPCBf+aOO/wzO3b4ZySptdU/E40m9l64eHEEBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQ3I0VaKipKLPfss/6Zm2/2zwwY4J956y3/TKI2b/bPzJrlnzl40D+D9MEREADABAUEADCR9AJ64oknFAgE4pbRifzCFABAWkvJOaCrrrpK77333jdv0o9TTQCAeClphn79+qmgoCAV3xoAkCZScg5oz549Kioq0ogRI3TXXXdp3759Xa4bjUYViUTiFgBA+kt6AZWVlammpkYbNmzQyy+/rObmZl1//fVqa2vrdP3q6mqFQqHYUlxcnOyRAAA9UMA551L5BkeOHNHw4cP1zDPP6N577z3r9Wg0qmg0GnsciUS+KqGwpKxUjoY01tN/DmjwYP9Mav+kxuPngHBhIpJCCofDysrq+nM85VcHZGdn68orr1RTU1OnrweDQQWDwVSPAQDoYVL+c0BHjx7V3r17VVhYmOq3AgD0IkkvoIceekj19fX65JNP9Oc//1m33nqr+vbtqzvuuCPZbwUA6MWS/k9wn332me644w4dPnxYQ4YM0XXXXactW7ZoyJAhyX4rAEAvlvKLEHxFIhGFQiFxEUJ6ys72z9x9t3/mF7/wz0hSZmZiOV+vvuqf+eMf/TMDB/pnJGnlSv/Mjh3+mbIy/wx6g/O7CIF7wQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADCR8l9Ih/R1jnsMdul3v/PPXHONf6Y7/dd/+WcefNA/88UX/plEjRrln3nooeTPgfTGERAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAR3w0bC1qzxz5SX+2ec8898+ql/RpKWL/fP/M//+Ge6887WiejXTZ8MY8f6Zz78MPlzwAZHQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAEwEnEvkVo+pE4lEFAqFJIUlZVmPc1EYNy6x3M6d/plTp/wztbX+mRde8M9I0u9+l1iupxo0KLFcIjdzHTjQP5PofOjpIpJCCofDysrq+nOcIyAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAm+lkPAHv/93+J5RYu9M/84Q/+mY8/9s/gtH4J/gm/7DL/TLrdyBWpxxEQAMAEBQQAMOFdQJs2bdL06dNVVFSkQCCgdevWxb3unNPjjz+uwsJCDRw4UBUVFdqzZ0+y5gUApAnvAmpvb1dpaalWrFjR6evLly/X888/r5UrV2rr1q0aNGiQpk6dquPHj1/wsACA9OF9irKyslKVlZWdvuac03PPPadHH31Ut9xyiyTp1VdfVX5+vtatW6dZs2Zd2LQAgLSR1HNAzc3NamlpUUVFRey5UCiksrIyNTQ0dJqJRqOKRCJxCwAg/SW1gFpaWiRJ+fn5cc/n5+fHXjtTdXW1QqFQbCkuLk7mSACAHsr8KrglS5YoHA7Hlv3791uPBADoBkktoIKCAklSa2tr3POtra2x184UDAaVlZUVtwAA0l9SC6ikpEQFBQWqra2NPReJRLR161aVl5cn860AAL2c91VwR48eVVNTU+xxc3Ozdu7cqZycHA0bNkwLFizQL37xC11xxRUqKSnRY489pqKiIs2YMSOZcwMAejnvAtq2bZtuuumm2ONFixZJkmbPnq2amhotXrxY7e3tuv/++3XkyBFdd9112rBhgwYMGJC8qQEAvV7AOeesh/i2SCSiUCgkKSyJ80HAhaipSSz3z//sn6mq8s+sXOmfQW8QkRRSOBw+53l986vgAAAXJwoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACe9fxwDARlmZf+af/imx99q50z+zalVi74WLF0dAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATHAzUuACTZ7sn7n+ev9MVZV/Jhj0z0jShg3+mWg0sffCxYsjIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACa4GSl6vHnz/DP/8i+Jvdff/31iOV+BgH/GueTP0ZX58/0zfRL46+yTT/pnvvzSP4OeiSMgAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJrgZKbrVVVf5Z/7jP/wzAwb4Z6Tuu+FnNOqfefRR/8zGjf4ZSXrwQf/M4sX+mURuyvrII/4Z9EwcAQEATFBAAAAT3gW0adMmTZ8+XUVFRQoEAlq3bl3c63PmzFEgEIhbpk2blqx5AQBpwruA2tvbVVpaqhUrVnS5zrRp03Tw4MHY8vrrr1/QkACA9ON9EUJlZaUqKyvPuU4wGFRBQUHCQwEA0l9KzgHV1dUpLy9Po0aN0rx583T48OEu141Go4pEInELACD9Jb2Apk2bpldffVW1tbX69a9/rfr6elVWVurUqVOdrl9dXa1QKBRbiouLkz0SAKAHSvrPAc2aNSv29dixYzVu3DiNHDlSdXV1mjx58lnrL1myRIsWLYo9jkQilBAAXARSfhn2iBEjlJubq6ampk5fDwaDysrKilsAAOkv5QX02Wef6fDhwyosLEz1WwEAehHvf4I7evRo3NFMc3Ozdu7cqZycHOXk5GjZsmWaOXOmCgoKtHfvXi1evFiXX365pk6dmtTBAQC9m3cBbdu2TTfddFPs8dfnb2bPnq2XX35Zu3bt0iuvvKIjR46oqKhIU6ZM0VNPPaVgMJi8qQEAvV7Aue66/eL5iUQiCoVCksKSOB+UbubN88+8+GLy5+hKIjcJ3bbNP3PPPf6ZvXv9M4nq29c/s3lz8ufozHXX+We6uAgXKRORFFI4HD7neX3uBQcAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMJH0X8kNnMsf/uCfWbfOP/PFF/4ZSfrlL/0zn3yS2Hv1ZIncPfqll/wzr7zin/m7v/PPfPihfwapxxEQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAE9yMFAnLz/fPlJT4Z2bO9M+g+yV6A1hcvDgCAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIKbkUJDhyaW+9//9c/k5Phn/vM//TP/+q/+GUlqb08sB2ngQP9MIOCfGTXKP/Phh/4ZpB5HQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExwM1LoqacSy2Vn+2ec88/MmeOfOX7cPyNJS5b4ZyKRxN6rJxs0yD/z7//un0lkf7j6av/Mf/+3fwapxxEQAMAEBQQAMOFVQNXV1ZowYYIyMzOVl5enGTNmqLGxMW6d48ePq6qqSoMHD9all16qmTNnqrW1NalDAwB6P68Cqq+vV1VVlbZs2aJ3331XJ0+e1JQpU9T+rd/itXDhQr399ttas2aN6uvrdeDAAd12221JHxwA0Lt5XYSwYcOGuMc1NTXKy8vT9u3bNWnSJIXDYf3mN7/R6tWrdfPNN0uSVq1apR/84AfasmWLrrnmmuRNDgDo1S7oHFA4HJYk5Xz1e5a3b9+ukydPqqKiIrbO6NGjNWzYMDU0NHT6PaLRqCKRSNwCAEh/CRdQR0eHFixYoGuvvVZjxoyRJLW0tCgjI0PZZ1yfm5+fr5aWlk6/T3V1tUKhUGwpLi5OdCQAQC+ScAFVVVVp9+7deuONNy5ogCVLligcDseW/fv3X9D3AwD0Dgn9IOr8+fP1zjvvaNOmTRo6dGjs+YKCAp04cUJHjhyJOwpqbW1VQUFBp98rGAwqGAwmMgYAoBfzOgJyzmn+/Plau3atNm7cqJKSkrjXx48fr/79+6u2tjb2XGNjo/bt26fy8vLkTAwASAteR0BVVVVavXq11q9fr8zMzNh5nVAopIEDByoUCunee+/VokWLlJOTo6ysLD3wwAMqLy/nCjgAQByvAnr55ZclSTfeeGPc86tWrdKcr27Y9eyzz6pPnz6aOXOmotGopk6dqpdeeikpwwIA0kfAuURuB5g6kUhEoVBIUlhSlvU4F4WNGxPL3XCDf+aXv/TP/Nu/+WcStXKlfyaRm7kePuyfOXnSP5OR4Z+RpMWL/TPLlvlnPvzQP3PG33/Py5Ej/hlciIikkMLhsLKyuv4c515wAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATCf1GVKSXP/4xsVx33Q172DD/zPTp/hlJmju3ezIffeSf+eIL/8yQIf4ZSbrySv9MW5t/Zt48/wx3tk4fHAEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwwc1Iod27u++9olH/zJw5/plx4/wzkvQP/+Cfuflm/0xOjn/mppv8M4lK5Mai//iP/pmGBv8M0gdHQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAEwEnHPOeohvi0QiCoVCksKSsqzHAQB4i0gKKRwOKyur689xjoAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGDCq4Cqq6s1YcIEZWZmKi8vTzNmzFBjY2PcOjfeeKMCgUDcMnfu3KQODQDo/bwKqL6+XlVVVdqyZYveffddnTx5UlOmTFF7e3vcevfdd58OHjwYW5YvX57UoQEAvV8/n5U3bNgQ97impkZ5eXnavn27Jk2aFHv+kksuUUFBQXImBACkpQs6BxQOhyVJOTk5cc+/9tprys3N1ZgxY7RkyRIdO3asy+8RjUYViUTiFgBA+vM6Avq2jo4OLViwQNdee63GjBkTe/7OO+/U8OHDVVRUpF27dunhhx9WY2Oj3nrrrU6/T3V1tZYtW5boGACAXirgnHOJBOfNm6ff//732rx5s4YOHdrlehs3btTkyZPV1NSkkSNHnvV6NBpVNBqNPY5EIiouLpYUlpSVyGgAAFMRSSGFw2FlZXX9OZ7QEdD8+fP1zjvvaNOmTecsH0kqKyuTpC4LKBgMKhgMJjIGAKAX8yog55weeOABrV27VnV1dSopKfnOzM6dOyVJhYWFCQ0IAEhPXgVUVVWl1atXa/369crMzFRLS4skKRQKaeDAgdq7d69Wr16tH//4xxo8eLB27dqlhQsXatKkSRo3blxK/gMAAL2T1zmgQCDQ6fOrVq3SnDlztH//ft19993avXu32tvbVVxcrFtvvVWPPvroOf8d8NsikYhCoZA4BwQAvdX5nQNK+CKEVKGAAKC3O78C4l5wAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAAT/awHOJNz7quvIqZzAAASdfrz+5vP8871uAJqa2v76qti0zkAABemra1NoVCoy9cD7rsqqpt1dHTowIEDyszMVCAQiHstEomouLhY+/fvV1ZWltGE9tgOp7EdTmM7nMZ2OK0nbAfnnNra2lRUVKQ+fbo+09PjjoD69OmjoUOHnnOdrKysi3oH+xrb4TS2w2lsh9PYDqdZb4dzHfl8jYsQAAAmKCAAgIleVUDBYFBLly5VMBi0HsUU2+E0tsNpbIfT2A6n9abt0OMuQgAAXBx61REQACB9UEAAABMUEADABAUEADDRawpoxYoV+v73v68BAwaorKxMf/nLX6xH6nZPPPGEAoFA3DJ69GjrsVJu06ZNmj59uoqKihQIBLRu3bq4151zevzxx1VYWKiBAweqoqJCe/bssRk2hb5rO8yZM+es/WPatGk2w6ZIdXW1JkyYoMzMTOXl5WnGjBlqbGyMW+f48eOqqqrS4MGDdemll2rmzJlqbW01mjg1zmc73HjjjWftD3PnzjWauHO9ooDefPNNLVq0SEuXLtUHH3yg0tJSTZ06VYcOHbIerdtdddVVOnjwYGzZvHmz9Ugp197ertLSUq1YsaLT15cvX67nn39eK1eu1NatWzVo0CBNnTpVx48f7+ZJU+u7toMkTZs2LW7/eP3117txwtSrr69XVVWVtmzZonfffVcnT57UlClT1N7eHltn4cKFevvtt7VmzRrV19frwIEDuu222wynTr7z2Q6SdN9998XtD8uXLzeauAuuF5g4caKrqqqKPT516pQrKipy1dXVhlN1v6VLl7rS0lLrMUxJcmvXro097ujocAUFBe7pp5+OPXfkyBEXDAbd66+/bjBh9zhzOzjn3OzZs90tt9xiMo+VQ4cOOUmuvr7eOXf6/33//v3dmjVrYut89NFHTpJraGiwGjPlztwOzjl3ww03uJ/+9Kd2Q52HHn8EdOLECW3fvl0VFRWx5/r06aOKigo1NDQYTmZjz549Kioq0ogRI3TXXXdp37591iOZam5uVktLS9z+EQqFVFZWdlHuH3V1dcrLy9OoUaM0b948HT582HqklAqHw5KknJwcSdL27dt18uTJuP1h9OjRGjZsWFrvD2duh6+99tprys3N1ZgxY7RkyRIdO3bMYrwu9bibkZ7p888/16lTp5Sfnx/3fH5+vj7++GOjqWyUlZWppqZGo0aN0sGDB7Vs2TJdf/312r17tzIzM63HM9HS0iJJne4fX792sZg2bZpuu+02lZSUaO/evfr5z3+uyspKNTQ0qG/fvtbjJV1HR4cWLFiga6+9VmPGjJF0en/IyMhQdnZ23LrpvD90th0k6c4779Tw4cNVVFSkXbt26eGHH1ZjY6Peeustw2nj9fgCwjcqKytjX48bN05lZWUaPny4fvvb3+ree+81nAw9waxZs2Jfjx07VuPGjdPIkSNVV1enyZMnG06WGlVVVdq9e/dFcR70XLraDvfff3/s67Fjx6qwsFCTJ0/W3r17NXLkyO4es1M9/p/gcnNz1bdv37OuYmltbVVBQYHRVD1Ddna2rrzySjU1NVmPYubrfYD942wjRoxQbm5uWu4f8+fP1zvvvKP3338/7te3FBQU6MSJEzpy5Ejc+um6P3S1HTpTVlYmST1qf+jxBZSRkaHx48ertrY29lxHR4dqa2tVXl5uOJm9o0ePau/evSosLLQexUxJSYkKCgri9o9IJKKtW7de9PvHZ599psOHD6fV/uGc0/z587V27Vpt3LhRJSUlca+PHz9e/fv3j9sfGhsbtW/fvrTaH75rO3Rm586dktSz9gfrqyDOxxtvvOGCwaCrqalxf/3rX93999/vsrOzXUtLi/Vo3erBBx90dXV1rrm52f3pT39yFRUVLjc31x06dMh6tJRqa2tzO3bscDt27HCS3DPPPON27NjhPv30U+ecc7/61a9cdna2W79+vdu1a5e75ZZbXElJifvyyy+NJ0+uc22HtrY299BDD7mGhgbX3Nzs3nvvPfejH/3IXXHFFe748ePWoyfNvHnzXCgUcnV1de7gwYOx5dixY7F15s6d64YNG+Y2btzotm3b5srLy115ebnh1Mn3XduhqanJPfnkk27btm2uubnZrV+/3o0YMcJNmjTJePJ4vaKAnHPuhRdecMOGDXMZGRlu4sSJbsuWLdYjdbvbb7/dFRYWuoyMDPe9733P3X777a6pqcl6rJR7//33naSzltmzZzvnTl+K/dhjj7n8/HwXDAbd5MmTXWNjo+3QKXCu7XDs2DE3ZcoUN2TIENe/f383fPhwd99996XdX9I6+++X5FatWhVb58svv3Q/+clP3GWXXeYuueQSd+utt7qDBw/aDZ0C37Ud9u3b5yZNmuRycnJcMBh0l19+ufvZz37mwuGw7eBn4NcxAABM9PhzQACA9EQBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMDE/wOu3cgKs1oZfAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "dataset_name = \"MNIST\"  # You can change this to \"FMNIST\", \"CIFAR10\", \"CIFAR100\", etc.\n",
    "train_images, train_labels, test_images, test_labels = utils.load_full_datasets(dataset_name)\n",
    "\n",
    "# Define parameters for split_feature_skew\n",
    "client_number = 10\n",
    "set_rotation = True\n",
    "rotations = 4\n",
    "scaling_rotation_low = 0.1\n",
    "scaling_rotation_high = 0.2\n",
    "set_color = True\n",
    "colors = 3\n",
    "scaling_color_low = 0.1\n",
    "scaling_color_high = 0.2\n",
    "random_order = True\n",
    "\n",
    "# Run split_feature_skew\n",
    "clients_data = utils.split_feature_skew(\n",
    "    train_features = train_images,\n",
    "    train_labels = train_labels,\n",
    "    test_features = test_images,\n",
    "    test_labels = test_labels,\n",
    "    client_number = client_number,\n",
    "    set_rotation = set_rotation,\n",
    "    rotations = rotations,\n",
    "    scaling_rotation_low = scaling_rotation_low,\n",
    "    scaling_rotation_high = scaling_rotation_high,\n",
    "    set_color = set_color,\n",
    "    colors = colors,\n",
    "    scaling_color_low = scaling_color_low,\n",
    "    scaling_color_high = scaling_color_high,\n",
    "    random_order = random_order\n",
    ")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Example: Visualize the first image from the first client\n",
    "plt.imshow(clients_data[0]['train_features'][0].permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6000, 3, 28, 28])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_data[0]['train_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 0, ..., 4, 4, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_data[0]['train_labels'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_data[0]['train_labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clients_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_features', 'train_labels', 'test_features', 'test_labels'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100, 10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup tensorflow model structure\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from util import *\n",
    "import cifar10 \n",
    "\n",
    "\n",
    "\n",
    "class TrainCIFARCluster(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        assert self.config['m'] % self.config['p'] == 0\n",
    "\n",
    "    def set_random_seed(seed):\n",
    "        np.random.seed(seed)\n",
    "        tf.set_random_seed(seed)\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        os.makedirs(self.config['project_dir'], exist_ok = True)\n",
    "\n",
    "        self.result_fname = os.path.join(self.config['project_dir'], 'results')\n",
    "        self.checkpoint_fname = os.path.join(self.config['project_dir'], 'checkpoint')\n",
    "\n",
    "        set_random_seed(self.config['data_seed'])\n",
    "        self.setup_datasets()\n",
    "        self.setup_model()\n",
    "\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "        set_random_seed(self.config['data_seed']+self.config['train_seed'])\n",
    "        self.initialize_models()\n",
    "        self.initialize_assign_ops()\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        self.epoch = None\n",
    "        self.lr = None\n",
    "\n",
    "\n",
    "    def setup_datasets(self):\n",
    "        # tf.enable_eager_execution()\n",
    "\n",
    "        # generate indices for each dataset\n",
    "        # also write cluster info\n",
    "\n",
    "        # CIFAR10_TRAINSET_DATA_SIZE = 50000  #!!\n",
    "        # CIFAR10_TESTSET_DATA_SIZE = 10000\n",
    "        CIFAR10_TRAINSET_DATA_SIZE = 2500  #!!\n",
    "        CIFAR10_TESTSET_DATA_SIZE = 2500\n",
    "\n",
    "        cfg = self.config\n",
    "\n",
    "        self.dataset = {}\n",
    "        self.our_dataset = our_data_creation()\n",
    "\n",
    "        dataset = {}\n",
    "        dataset['data_indices'], dataset['cluster_assign'] = \\\n",
    "            self._setup_dataset(CIFAR10_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
    "        dl = self._load_CIFAR(train=True)\n",
    "        dataset['data_loader'] = dl\n",
    "        self.dataset['train'] = dataset\n",
    "\n",
    "        dataset = {}\n",
    "        dataset['data_indices'], dataset['cluster_assign'] = \\\n",
    "            self._setup_dataset(CIFAR10_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'], random=False)\n",
    "        dl = self._load_CIFAR(train=False)\n",
    "        dataset['data_loader'] = dl\n",
    "        self.dataset['test'] = dataset\n",
    "\n",
    "        # tf.disable_eager_execution()\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "\n",
    "    def _setup_dataset(self, num_data, p, m, n, random = True):\n",
    "\n",
    "        assert (m // p) * n == num_data\n",
    "\n",
    "        dataset = {}\n",
    "\n",
    "        cfg = self.config\n",
    "\n",
    "        data_indices = []\n",
    "        cluster_assign = []\n",
    "\n",
    "        m_per_cluster = m // p\n",
    "\n",
    "        for p_i in range(p):\n",
    "\n",
    "            if random:\n",
    "                ll = list(np.random.permutation(num_data))\n",
    "            else:\n",
    "                ll = list(range(num_data))\n",
    "\n",
    "            ll2 = chunkify(ll, m_per_cluster) # splits ll into m lists with size n\n",
    "            data_indices += ll2\n",
    "\n",
    "            cluster_assign += [p_i for _ in range(m_per_cluster)]\n",
    "\n",
    "        data_indices = np.array(data_indices)\n",
    "        cluster_assign = np.array(cluster_assign)\n",
    "        assert data_indices.shape[0] == cluster_assign.shape[0]\n",
    "        print(data_indices.shape)\n",
    "        print(m)\n",
    "        assert data_indices.shape[0] == m\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        return data_indices, cluster_assign\n",
    "\n",
    "\n",
    "    def _load_CIFAR(self, train=True):\n",
    "        # gives dataloader that gives (X,y) based on asked index\n",
    "\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "        # (50000, 32,32, 3) [0~1] , (50000, 1)\n",
    "\n",
    "        if train:\n",
    "            X = x_train / 255.0\n",
    "            y = y_train.reshape(-1)\n",
    "        else:\n",
    "            X = x_test / 255.0\n",
    "            y = y_test.reshape(-1)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def setup_model(self):\n",
    "\n",
    "        # setup tensorflow model structure\n",
    "\n",
    "        # self.x_pl = tf.placeholder(tf.float32, shape=(None, 24, 24, 3), name='input_x')\n",
    "        self.x_pl = tf.placeholder(tf.float32, shape=(None, 28, 28, 3), name='input_x')   # !!!\n",
    "        self.y_pl = tf.placeholder(tf.int32, shape=(None, ), name='output_y')\n",
    "        self.lr_pl = tf.placeholder(tf.float32, shape=(), name='learning_rate')\n",
    "\n",
    "        self.y_logits = cifar10.inference(self.x_pl) # construct model\n",
    "        self.loss = cifar10.loss(self.y_logits, self.y_pl)\n",
    "\n",
    "        self.y_pred = tf.cast(tf.argmax(self.y_logits, 1), tf.int32)\n",
    "        self.correct_prediction = tf.equal(self.y_pred, self.y_pl) # used for accuracy\n",
    "        self.num_correct = tf.reduce_sum(tf.cast(self.correct_prediction, tf.int64))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.lr_pl)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "        self.opt_reset_op = tf.variables_initializer(self.optimizer.variables())\n",
    "\n",
    "        # import ipdb; ipdb.set_trace() # check self.optimizer.variables()\n",
    "\n",
    "        self.metrics = { # used by self.eval()\n",
    "            'loss':self.loss,\n",
    "            'correct': self.num_correct,\n",
    "            # and add more...\n",
    "        }\n",
    "\n",
    "\n",
    "        # transform ops\n",
    "        self.x_tr_pl = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))           # !!!!!!\n",
    "        # self.x_tr_pl = tf.placeholder(tf.float32, shape=(None, 28, 28, 3))\n",
    "        # with tf.device('/cpu:0'):\n",
    "        self.train_transform_op = train_transform(self.x_tr_pl) \n",
    "        self.test_transform_op = test_transform(self.x_tr_pl) \n",
    "\n",
    "\n",
    "    def initialize_models(self):\n",
    "\n",
    "        p = self.config['p']\n",
    "\n",
    "        # initialize p times, to get p different sets of weights.\n",
    "\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "\n",
    "        self.model_weights = []\n",
    "        for p_i in range(p):\n",
    "            self.sess.run(self.init_op)\n",
    "            weights = self.get_model_weights()\n",
    "            self.model_weights.append(weights)\n",
    "\n",
    "\n",
    "    IMAGE_SIZE = 28 # !!! was 24\n",
    "\n",
    "    def train_transform(reshaped_image):\n",
    "        # copied from cifar10_input.py / distorted_input()\n",
    "\n",
    "        height = IMAGE_SIZE\n",
    "        width = IMAGE_SIZE\n",
    "\n",
    "        # Image processing for training the network. Note the many random\n",
    "        # distortions applied to the image.\n",
    "\n",
    "        # Randomly crop a [height, width] section of the image.\n",
    "        distorted_image = tf.random_crop(reshaped_image, [tf.shape(reshaped_image)[0], height, width, 3])\n",
    "        # tf shape gives dynamic shape\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "        # Because these operations are not commutative, consider randomizing\n",
    "        # the order their operation.\n",
    "        distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                                max_delta=63)\n",
    "        distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                                lower=0.2, upper=1.8)\n",
    "\n",
    "        # Subtract off the mean and divide by the variance of the pixels.\n",
    "        float_image = tf.image.per_image_standardization(distorted_image)\n",
    "\n",
    "        return float_image\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    arg_seed = 0\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--project-dir\",type=str,default=\"output\")\n",
    "    parser.add_argument(\"--dataset-dir\",type=str,default=\"output\")\n",
    "    # parser.add_argument(\"--num-epochs\",type=float,default=)\n",
    "    # parser.add_argument(\"--lr\",type=float,default=0.2)\n",
    "    parser.add_argument(\"--data-seed\",type=int,default=0)\n",
    "    parser.add_argument(\"--train-seed\",type=int,default=arg_seed)\n",
    "    parser.add_argument(\"--config-override\",type=str,default=\"\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # read config json and update the sysarg\n",
    "    with open(\"config.json\", \"r\") as read_file:\n",
    "        config = json.load(read_file)\n",
    "\n",
    "    args_dict = vars(args)\n",
    "    config.update(args_dict)\n",
    "\n",
    "    if config[\"config_override\"] == \"\":\n",
    "        del config['config_override']\n",
    "    else:\n",
    "        print(config['config_override'])\n",
    "        config_override = json.loads(config['config_override'])\n",
    "        del config['config_override']\n",
    "        config.update(config_override)\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'m': 10, 'm_test': 10, 'p': 2, 'n': 500, 'participation_rate': 1, 'num_epochs': 600, 'batch_size': 50, 'tau': 5, 'lr': 0.25, 'data_seed': 0, 'train_seed': 0}\n"
     ]
    }
   ],
   "source": [
    "    config = {\n",
    "        \"m\" : 10,  \n",
    "        \"m_test\" : 10,\n",
    "        \"p\" : 2,\n",
    "        \"n\" : 500,\n",
    "\n",
    "        \"participation_rate\":1,\n",
    "\n",
    "        \"num_epochs\": 600,\n",
    "\n",
    "        \"batch_size\":50,\n",
    "        \"tau\":5,\n",
    "        \"lr\":0.25,\n",
    "\n",
    "        \"data_seed\":0,\n",
    "        \"train_seed\":0,\n",
    "\n",
    "        \"data_seed\":0, # seed for data generation\n",
    "        \"train_seed\":0 # seed for training\n",
    "    }\n",
    "    config['train_seed'] = config['data_seed']\n",
    "    print(\"config:\",config)\n",
    "\n",
    "    exp = TrainCIFARCluster(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'project_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2356113/3135168685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2356113/4091706358.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'project_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'project_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'project_dir'"
     ]
    }
   ],
   "source": [
    "    exp.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_2356113/4091706358.py:148: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dario/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py:218: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dario/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py:142: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/dario/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py:118: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dario/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py:147: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dario/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py:100: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dario/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py:102: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dario/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py:230: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dario/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py:317: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_2356113/4091706358.py:160: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_2356113/4091706358.py:162: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2356113/2414506407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2356113/4091706358.py\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# self.x_tr_pl = tf.placeholder(tf.float32, shape=(None, 28, 28, 3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# with tf.device('/cpu:0'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_transform_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_tr_pl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_transform_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_tr_pl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_transform' is not defined"
     ]
    }
   ],
   "source": [
    "model = exp.setup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_config():\n",
    "    arg_seed = 0\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--project-dir\",type=str,default=\"output\")\n",
    "    parser.add_argument(\"--dataset-dir\",type=str,default=\"output\")\n",
    "    # parser.add_argument(\"--num-epochs\",type=float,default=)\n",
    "    # parser.add_argument(\"--lr\",type=float,default=0.2)\n",
    "    parser.add_argument(\"--data-seed\",type=int,default=0)\n",
    "    parser.add_argument(\"--train-seed\",type=int,default=arg_seed)\n",
    "    parser.add_argument(\"--config-override\",type=str,default=\"\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # read config json and update the sysarg\n",
    "    with open(\"config.json\", \"r\") as read_file:\n",
    "        config = json.load(read_file)\n",
    "\n",
    "    args_dict = vars(args)\n",
    "    config.update(args_dict)\n",
    "\n",
    "    if config[\"config_override\"] == \"\":\n",
    "        del config['config_override']\n",
    "    else:\n",
    "        print(config['config_override'])\n",
    "        config_override = json.loads(config['config_override'])\n",
    "        del config['config_override']\n",
    "        config.update(config_override)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "class TrainCIFARCluster(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        assert self.config['m'] % self.config['p'] == 0\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        os.makedirs(self.config['project_dir'], exist_ok = True)\n",
    "\n",
    "        self.result_fname = os.path.join(self.config['project_dir'], 'results')\n",
    "        self.checkpoint_fname = os.path.join(self.config['project_dir'], 'checkpoint')\n",
    "\n",
    "        set_random_seed(self.config['data_seed'])\n",
    "        self.setup_datasets()\n",
    "        self.setup_model()\n",
    "\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "        set_random_seed(self.config['data_seed']+self.config['train_seed'])\n",
    "        self.initialize_models()\n",
    "        self.initialize_assign_ops()\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        self.epoch = None\n",
    "        self.lr = None\n",
    "\n",
    "\n",
    "    def setup_datasets(self):\n",
    "        # tf.enable_eager_execution()\n",
    "\n",
    "        # generate indices for each dataset\n",
    "        # also write cluster info\n",
    "\n",
    "        # CIFAR10_TRAINSET_DATA_SIZE = 50000  #!!\n",
    "        # CIFAR10_TESTSET_DATA_SIZE = 10000\n",
    "        CIFAR10_TRAINSET_DATA_SIZE = 2500  #!!\n",
    "        CIFAR10_TESTSET_DATA_SIZE = 2500\n",
    "\n",
    "        cfg = self.config\n",
    "\n",
    "        self.dataset = {}\n",
    "        self.our_dataset = our_data_creation()\n",
    "\n",
    "        dataset = {}\n",
    "        dataset['data_indices'], dataset['cluster_assign'] = \\\n",
    "            self._setup_dataset(CIFAR10_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
    "        dl = self._load_CIFAR(train=True)\n",
    "        dataset['data_loader'] = dl\n",
    "        self.dataset['train'] = dataset\n",
    "\n",
    "        dataset = {}\n",
    "        dataset['data_indices'], dataset['cluster_assign'] = \\\n",
    "            self._setup_dataset(CIFAR10_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'], random=False)\n",
    "        dl = self._load_CIFAR(train=False)\n",
    "        dataset['data_loader'] = dl\n",
    "        self.dataset['test'] = dataset\n",
    "\n",
    "        # tf.disable_eager_execution()\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "\n",
    "    def _setup_dataset(self, num_data, p, m, n, random = True):\n",
    "\n",
    "        assert (m // p) * n == num_data\n",
    "\n",
    "        dataset = {}\n",
    "\n",
    "        cfg = self.config\n",
    "\n",
    "        data_indices = []\n",
    "        cluster_assign = []\n",
    "\n",
    "        m_per_cluster = m // p\n",
    "\n",
    "        for p_i in range(p):\n",
    "\n",
    "            if random:\n",
    "                ll = list(np.random.permutation(num_data))\n",
    "            else:\n",
    "                ll = list(range(num_data))\n",
    "\n",
    "            ll2 = chunkify(ll, m_per_cluster) # splits ll into m lists with size n\n",
    "            data_indices += ll2\n",
    "\n",
    "            cluster_assign += [p_i for _ in range(m_per_cluster)]\n",
    "\n",
    "        data_indices = np.array(data_indices)\n",
    "        cluster_assign = np.array(cluster_assign)\n",
    "        assert data_indices.shape[0] == cluster_assign.shape[0]\n",
    "        print(data_indices.shape)\n",
    "        print(m)\n",
    "        assert data_indices.shape[0] == m\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        return data_indices, cluster_assign\n",
    "\n",
    "\n",
    "    def _load_CIFAR(self, train=True):\n",
    "        # gives dataloader that gives (X,y) based on asked index\n",
    "\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "        # (50000, 32,32, 3) [0~1] , (50000, 1)\n",
    "\n",
    "        if train:\n",
    "            X = x_train / 255.0\n",
    "            y = y_train.reshape(-1)\n",
    "        else:\n",
    "            X = x_test / 255.0\n",
    "            y = y_test.reshape(-1)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def setup_model(self):\n",
    "\n",
    "        # setup tensorflow model structure\n",
    "\n",
    "        # self.x_pl = tf.placeholder(tf.float32, shape=(None, 24, 24, 3), name='input_x')\n",
    "        self.x_pl = tf.placeholder(tf.float32, shape=(None, 28, 28, 3), name='input_x')   # !!!\n",
    "        self.y_pl = tf.placeholder(tf.int32, shape=(None, ), name='output_y')\n",
    "        self.lr_pl = tf.placeholder(tf.float32, shape=(), name='learning_rate')\n",
    "\n",
    "        self.y_logits = cifar10.inference(self.x_pl) # construct model\n",
    "        self.loss = cifar10.loss(self.y_logits, self.y_pl)\n",
    "\n",
    "        self.y_pred = tf.cast(tf.argmax(self.y_logits, 1), tf.int32)\n",
    "        self.correct_prediction = tf.equal(self.y_pred, self.y_pl) # used for accuracy\n",
    "        self.num_correct = tf.reduce_sum(tf.cast(self.correct_prediction, tf.int64))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.lr_pl)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "        self.opt_reset_op = tf.variables_initializer(self.optimizer.variables())\n",
    "\n",
    "        # import ipdb; ipdb.set_trace() # check self.optimizer.variables()\n",
    "\n",
    "        self.metrics = { # used by self.eval()\n",
    "            'loss':self.loss,\n",
    "            'correct': self.num_correct,\n",
    "            # and add more...\n",
    "        }\n",
    "\n",
    "\n",
    "        # transform ops\n",
    "        self.x_tr_pl = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))           # !!!!!!\n",
    "        # self.x_tr_pl = tf.placeholder(tf.float32, shape=(None, 28, 28, 3))\n",
    "        # with tf.device('/cpu:0'):\n",
    "        self.train_transform_op = train_transform(self.x_tr_pl) \n",
    "        self.test_transform_op = test_transform(self.x_tr_pl) \n",
    "\n",
    "\n",
    "    def initialize_models(self):\n",
    "\n",
    "        p = self.config['p']\n",
    "\n",
    "        # initialize p times, to get p different sets of weights.\n",
    "\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "\n",
    "        self.model_weights = []\n",
    "        for p_i in range(p):\n",
    "            self.sess.run(self.init_op)\n",
    "            weights = self.get_model_weights()\n",
    "            self.model_weights.append(weights)\n",
    "\n",
    "    def get_model_weights(self):\n",
    "        self.collection = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "\n",
    "        names = [var.name for var in self.collection]\n",
    "        weights_arrays = self.sess.run(self.collection)\n",
    "\n",
    "        weights = dict(zip(names, weights_arrays))\n",
    "        # {'conv1/weights:0': np.array, ...}\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def initialize_assign_ops(self):\n",
    "        self.collection = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "\n",
    "        assign_ops = {}\n",
    "        assign_pls = {}\n",
    "        for var in self.collection:\n",
    "            # import ipdb; ipdb.set_trace()\n",
    "            pl = tf.placeholder(tf.float32, shape=var.shape)\n",
    "            assign_pls[var.name] = pl\n",
    "\n",
    "            op = tf.compat.v1.assign(var, pl)\n",
    "            assign_ops[var.name] = op\n",
    "\n",
    "\n",
    "        self.assign_ops = assign_ops\n",
    "        self.assign_pls = assign_pls\n",
    "\n",
    "    def put_model_weights(self, weights):\n",
    "\n",
    "        assign_ops = []\n",
    "\n",
    "        fd = {}\n",
    "        for var_name in self.assign_pls:\n",
    "            # assign_op = tf.assign(var, weights[var.name])\n",
    "            pl = self.assign_pls[var_name]\n",
    "            fd[pl] = weights[var_name]\n",
    "\n",
    "        self.sess.run(self.opt_reset_op) # reset the optimizer state ?\n",
    "        self.sess.run(list(self.assign_ops.values()), feed_dict = fd)\n",
    "\n",
    "    def average_model_weights(self, weights_list):\n",
    "\n",
    "        w2 = {}\n",
    "\n",
    "        for key in weights_list[0].keys():\n",
    "\n",
    "            w2[key] = np.mean([w[key] for w in weights_list], axis=0)\n",
    "\n",
    "        return w2\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        TRAIN_INFER_FULL_NODES = 0\n",
    "\n",
    "        num_epochs = self.config['num_epochs']\n",
    "        lr = self.config['lr']\n",
    "\n",
    "        results = []\n",
    "\n",
    "        # epoch -1\n",
    "        self.epoch = -1\n",
    "\n",
    "        print(\"initial test0\")\n",
    "\n",
    "        # self.find_good_initializer()   #!!!\n",
    "\n",
    "        result = {}\n",
    "        result['epoch'] = -1\n",
    "\n",
    "        t0 = time.time()\n",
    "        print(\"initial test1\")\n",
    "        self.set_participating_nodes()\n",
    "        print(\"initial test1.1\")\n",
    "        res = self.test(train=True, force_full_nodes =TRAIN_INFER_FULL_NODES)\n",
    "        print(\"initial test1.2\")\n",
    "        # res = self.test(train=True)\n",
    "        t1 = time.time()\n",
    "        res['infer_time'] = t1-t0\n",
    "        result['train'] = res\n",
    "\n",
    "        self.print_epoch_stats(res)\n",
    "\n",
    "        print(\"initial test2\")\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "        res = self.test(train=False)\n",
    "    \n",
    "        print(\"initial test3\")\n",
    "\n",
    "        t1 = time.time()\n",
    "        res['infer_time'] = t1-t0\n",
    "        result['test'] = res\n",
    "        self.print_epoch_stats(res)\n",
    "        results.append(result)\n",
    "\n",
    "        # this will be used in next epoch\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.epoch = epoch\n",
    "\n",
    "            result = {}\n",
    "            result['epoch'] = epoch\n",
    "\n",
    "            lr = self.lr_schedule(epoch)\n",
    "            result['lr'] = lr\n",
    "\n",
    "            t0 = time.time()\n",
    "            print(\"initial test4\")\n",
    "\n",
    "            result['train'] = self.train(lr = lr)\n",
    "            t1 = time.time()\n",
    "            train_time = t1-t0\n",
    "\n",
    "            t0 = time.time()\n",
    "            self.set_participating_nodes()\n",
    "            # res = self.test(train=True)\n",
    "            print(\"initial test5\")\n",
    "\n",
    "            res = self.test(train=True, force_full_nodes =TRAIN_INFER_FULL_NODES)\n",
    "            t1 = time.time()\n",
    "            res['infer_time'] = t1-t0\n",
    "            res['train_time'] = train_time\n",
    "            res['lr'] = lr\n",
    "            result['train'] = res\n",
    "\n",
    "            self.print_epoch_stats(res)\n",
    "\n",
    "            t0 = time.time()\n",
    "            res = self.test(train=False)\n",
    "            t1 = time.time()\n",
    "            res['infer_time'] = t1-t0\n",
    "            result['test'] = res\n",
    "            self.print_epoch_stats(res)\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "            if epoch % 10 == 0 or epoch == num_epochs - 1 :\n",
    "                with open(self.result_fname+\".pickle\", 'wb') as outfile:\n",
    "                    pickle.dump(results, outfile)\n",
    "                    print(f'result written at {self.result_fname+\".pickle\"}')\n",
    "                # self.save_checkpoint()\n",
    "                # print(f'checkpoint written at {self.checkpoint_fname}')\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "\n",
    "    def find_good_initializer(self):\n",
    "        print(\"finding good initializer from train data\")\n",
    "\n",
    "        cfg = self.config\n",
    "\n",
    "        if cfg['p'] == 4:\n",
    "            th = 0.1\n",
    "        elif cfg['p'] == 2:\n",
    "            th = 0.35\n",
    "        elif cfg['p'] == 1:\n",
    "            th = 0.0\n",
    "        else:\n",
    "            raise NotImplementedError(\"only p=1,2,4 supported\")\n",
    "\n",
    "        is_not_good = True\n",
    "        while is_not_good:\n",
    "            self.initialize_models()\n",
    "            t0 = time.time()\n",
    "            self.set_participating_nodes()\n",
    "            # res = self.test(train=True, force_full_nodes = True)\n",
    "            res = self.test(train=True)\n",
    "            t1 = time.time()\n",
    "            res['infer_time'] = t1-t0\n",
    "            self.print_epoch_stats(res)\n",
    "\n",
    "            cl_ct = res['cl_ct']\n",
    "\n",
    "            num_nodes = np.sum(cl_ct)\n",
    "            is_not_good = False\n",
    "            for ct in cl_ct:\n",
    "                if ct / num_nodes < th:\n",
    "                    is_not_good = True\n",
    "\n",
    "        print(\"found good initializer\")\n",
    "\n",
    "\n",
    "\n",
    "    def set_participating_nodes(self):\n",
    "        cfg = self.config\n",
    "        m = cfg['m']\n",
    "        p = cfg['p']\n",
    "        p_rate = cfg['participation_rate']\n",
    "\n",
    "        self.participating_nodes = np.random.choice(m, int(m * p_rate), replace = False)\n",
    "\n",
    "        return self.participating_nodes\n",
    "\n",
    "    def lr_schedule(self, epoch):\n",
    "        if self.lr is None:\n",
    "            self.lr = self.config['lr']\n",
    "\n",
    "        if epoch != 0 and LR_DECAY:\n",
    "            self.lr = self.lr * 0.99\n",
    "\n",
    "        return self.lr\n",
    "\n",
    "\n",
    "    def print_epoch_stats(self, res):\n",
    "        if res['is_train']:\n",
    "            data_str = 'tr'\n",
    "        else:\n",
    "            data_str = 'tst'\n",
    "\n",
    "        if 'train_time' in res:\n",
    "            time_str = f\"{res['train_time']:.3f}sec(train) {res['infer_time']:.3f}sec(infer)\"\n",
    "        else:\n",
    "            time_str = f\"{res['infer_time']:.3f}sec\"\n",
    "\n",
    "        if 'lr' in res:\n",
    "            lr_str = f\" lr {res['lr']:4f}\"\n",
    "        else:\n",
    "            lr_str = \"\"\n",
    "\n",
    "        if 'cl_ct' in res:\n",
    "            cl_str = f\" clct{res['cl_ct']} ans{res['cl_ct_ans']}\"\n",
    "        else:\n",
    "            cl_str = \"\"\n",
    "\n",
    "        str0 = f\"Epoch {self.epoch} {data_str}: l {res['loss']:.3f} a {res['acc']:.3f} {cl_str}{lr_str} {time_str}\"\n",
    "\n",
    "        print(str0)\n",
    "\n",
    "    def train(self, lr):\n",
    "\n",
    "        VERBOSE = 0\n",
    "\n",
    "        cfg = self.config\n",
    "        m = cfg['m']\n",
    "        p = cfg['p']\n",
    "        tau = cfg['tau']\n",
    "        n = cfg['n']\n",
    "        batch_size = cfg['batch_size']\n",
    "\n",
    "        participating_nodes = self.participating_nodes\n",
    "        cluster_assign = self.cluster_assign\n",
    "\n",
    "        t_put_weight = 0\n",
    "        t_get_weight = 0\n",
    "        time_load_data = 0\n",
    "        time_train = 0\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        updated_local_weights = []\n",
    "        for m_i2, m_i in enumerate(participating_nodes):\n",
    "            print(f'Local update m_i2 {m_i2}/{len(participating_nodes)} processing')\n",
    "            print(f'Machine {m_i} is processing')\n",
    "            p_i = cluster_assign[m_i]\n",
    "\n",
    "            # if VERBOSE and m_i2 % 1 == 0: print(f'Local update m_i2 {m_i2}/{len(participating_nodes)} processing \\r', end ='')\n",
    "            if VERBOSE and m_i2 % 1 == 0: print(f'Local update m_i2 {m_i2}/{len(participating_nodes)} processing')\n",
    "\n",
    "            # Local Update process\n",
    "\n",
    "            t_p = time.time()\n",
    "            self.put_model_weights(self.model_weights[p_i])\n",
    "            t_p1 = time.time()\n",
    "            t_put_weight += t_p1-t_p\n",
    "\n",
    "            for l_epoch in range(tau): # local epochs\n",
    "\n",
    "                pmt = np.random.permutation(n)\n",
    "                local_indices_list = create_batches(pmt, batch_size = batch_size)\n",
    "                node_data_indices = self.dataset['train']['data_indices'][m_i]\n",
    "\n",
    "                X_train = self.our_dataset[m_i2]['train_features']\n",
    "                y_train = self.our_dataset[m_i2]['train_labels']\n",
    "                # random shuffle\n",
    "                pmt2 = np.random.permutation(len(X_train))\n",
    "                X_train = X_train[pmt2]\n",
    "                y_train = y_train[pmt2]\n",
    "                # permute data from [6000, 3, 28, 28] to [6000, 28, 28, 3] \n",
    "                X_train = np.transpose(X_train, (0, 2, 3, 1))\n",
    "                # numpy \n",
    "                X_train = X_train.numpy()\n",
    "                y_train = y_train.numpy()\n",
    "                \n",
    "                # cycle across batches (use batch_size) - our implementation \n",
    "                for ii in range(0, len(X_train), batch_size):\n",
    "                    t00 = time.time()\n",
    "                    X_b = X_train[ii:ii+batch_size]\n",
    "                    y_b = y_train[ii:ii+batch_size]\n",
    "\n",
    "                    print(f'X_b shape: {X_b.shape}') #X_b shape: (50, 24, 24, 3)\n",
    "                    print(f'X_b type: {type(X_b)}') #X_b type: <class 'numpy.ndarray'>\n",
    "                    print(f'y_b shape: {y_b.shape}') #y_b shape: (50,)\n",
    "                    t01 = time.time()\n",
    "\n",
    "                    fd0 = {\n",
    "                        self.x_pl:X_b,\n",
    "                        self.y_pl:y_b,\n",
    "                        self.lr_pl:self.lr\n",
    "                    }\n",
    "                    self.sess.run([self.train_op], feed_dict= fd0)\n",
    "\n",
    "                    t02 = time.time()\n",
    "\n",
    "                    time_load_data += t01 - t00\n",
    "                    time_train += t02 - t01\n",
    "\n",
    "                # original implementation\n",
    "                # for b_i, local_indices in enumerate(local_indices_list):\n",
    "                #     t00 = time.time()\n",
    "\n",
    "                #     current_batch_indices = node_data_indices[local_indices]\n",
    "\n",
    "                #     (X_b, y_b) = self.load_data_by_index(current_batch_indices, m_i)     ####### !!!! Modify here to load our data for client m_i (partecipating). Inside this function they rotate the images with respect to dataset['cluster_assign']. So we can substitute this part directly with our dataset for each client\n",
    "                    \n",
    "                #     print(f'X_b shape: {X_b.shape}') #X_b shape: (50, 24, 24, 3)\n",
    "                #     print(f'X_b type: {type(X_b)}') #X_b type: <class 'numpy.ndarray'>\n",
    "                #     print(f'y_b shape: {y_b.shape}') #y_b shape: (50,)\n",
    "                #     t01 = time.time()\n",
    "\n",
    "                #     fd0 = {\n",
    "                #         self.x_pl:X_b,\n",
    "                #         self.y_pl:y_b,\n",
    "                #         self.lr_pl:self.lr\n",
    "                #     }\n",
    "                #     self.sess.run([self.train_op], feed_dict= fd0)\n",
    "\n",
    "                #     t02 = time.time()\n",
    "\n",
    "                #     time_load_data += t01 - t00\n",
    "                #     time_train += t02 - t01\n",
    "                \n",
    "\n",
    "\n",
    "            t_p = time.time()\n",
    "            updated_local_weight = self.get_model_weights()\n",
    "            t_p1 = time.time()\n",
    "            t_get_weight += t_p1-t_p\n",
    "\n",
    "            updated_local_weights.append(updated_local_weight)\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        # averaging\n",
    "\n",
    "\n",
    "        local_weights_cluster = [[] for _ in range(p)]\n",
    "\n",
    "        for m_i2, m_i in enumerate(participating_nodes):\n",
    "            p_i = cluster_assign[m_i]\n",
    "            local_weights_cluster[p_i].append(updated_local_weights[m_i2])\n",
    "\n",
    "        for p_i in range(p):\n",
    "            if len(local_weights_cluster[p_i]) > 0:\n",
    "                self.model_weights[p_i] = self.average_model_weights(local_weights_cluster[p_i])\n",
    "\n",
    "        t2 = time.time()\n",
    "\n",
    "        if VERBOSE: print(f\"train_whole {t1-t0:.3f} t_gd {time_train:.3f} t load data {time_load_data:.3f} t put model {t_put_weight:.3f} t get mdoel {t_get_weight:.3f}  averaging {t2-t1:.3f}\")\n",
    "\n",
    "    def test(self, train = True, force_full_nodes = False):\n",
    "\n",
    "        VERBOSE = 0\n",
    "\n",
    "        cfg = self.config\n",
    "        p = cfg['p']\n",
    "        p_rate = cfg['participation_rate']\n",
    "\n",
    "\n",
    "        if train:\n",
    "            m = cfg['m']\n",
    "            dataset = self.dataset['train']\n",
    "            if force_full_nodes:\n",
    "                participating_nodes = list(range(m))\n",
    "            else:\n",
    "                participating_nodes = self.participating_nodes\n",
    "        else:\n",
    "            m = cfg['m_test']\n",
    "            dataset = self.dataset['test']\n",
    "            participating_nodes = list(range(m))\n",
    "\n",
    "            # DEBUGGING\n",
    "            # print(\"DEBUGGING MODEe\")\n",
    "            # participating_nodes = np.random.choice(m, int(m * p_rate), replace = False)\n",
    "\n",
    "\n",
    "        # get loss and correct from all data\n",
    "        t_load_model = 0\n",
    "        t_load_data = 0\n",
    "        t_infer = 0\n",
    "\n",
    "        losses = {}\n",
    "        corrects = {}\n",
    "        for p_i in range(p):\n",
    "\n",
    "            tp0= time.time()\n",
    "            self.put_model_weights(self.model_weights[p_i])\n",
    "            tp1= time.time()\n",
    "            t_load_model += tp1-tp0\n",
    "\n",
    "            for m_i in participating_nodes:\n",
    "\n",
    "                t00= time.time()\n",
    "                # (X, y) = self.load_node_data(m_i, train=train) # load batch data rotated    #!!!\n",
    "\n",
    "                X_train = self.our_dataset[m_i]['train_features']\n",
    "                y_train = self.our_dataset[m_i]['train_labels']\n",
    "                # random shuffle\n",
    "                pmt2 = np.random.permutation(len(X_train))\n",
    "                X_train = X_train[pmt2]\n",
    "                y_train = y_train[pmt2]\n",
    "                # permute data from [6000, 3, 28, 28] to [6000, 28, 28, 3] \n",
    "                X_train = np.transpose(X_train, (0, 2, 3, 1))\n",
    "                # numpy \n",
    "                X = X_train.numpy()\n",
    "                y = y_train.numpy()\n",
    "                X = X[:500]\n",
    "                y = y[:500]\n",
    "\n",
    "                print(f'X shape: {X.shape}') #X shape: (500, 24, 24, 3)\n",
    "                t01= time.time()\n",
    "                t_load_data += t01-t00\n",
    "\n",
    "                ti0= time.time()\n",
    "                (loss, correct) = self.sess.run([self.loss, self.num_correct], feed_dict = {self.x_pl:X, self.y_pl:y})\n",
    "                ti1= time.time()\n",
    "                t_infer += ti1-ti0\n",
    "\n",
    "\n",
    "                losses[(m_i,p_i)] = loss\n",
    "                corrects[(m_i,p_i)] = correct\n",
    "\n",
    "\n",
    "        if VERBOSE: print(f\"loadmodel {t_load_model:.3f}, load data {t_load_data:.3f}, infer {t_infer:.3f}\")\n",
    "\n",
    "\n",
    "        # calculate loss and cluster the machines\n",
    "        cluster_assign = [-1 for _ in range(m)]\n",
    "        for m_i in participating_nodes:\n",
    "            machine_losses = [ losses[(m_i,p_i)] for p_i in range(p) ]\n",
    "            min_p_i = np.argmin(machine_losses)\n",
    "            cluster_assign[m_i] = min_p_i\n",
    "\n",
    "        # calculate optimal model's loss, acc over all models\n",
    "\n",
    "        num_data = len(participating_nodes) * cfg['n']\n",
    "        min_corrects = []\n",
    "        min_losses = []\n",
    "        for m_i in participating_nodes:\n",
    "            p_i = cluster_assign[m_i]\n",
    "\n",
    "            min_loss = losses[(m_i,p_i)]\n",
    "            min_losses.append(min_loss)\n",
    "\n",
    "            min_correct = corrects[(m_i,p_i)]\n",
    "            min_corrects.append(min_correct)\n",
    "\n",
    "        loss = np.mean(min_losses)\n",
    "        acc = np.sum(min_corrects) / num_data\n",
    "\n",
    "        # check cluster assignment acc\n",
    "        # cl_acc = np.mean(np.array(cluster_assign) == np.array(dataset['cluster_assign']))\n",
    "        cl_ct = [np.sum(np.array(cluster_assign) == p_i ) for p_i in range(p)]\n",
    "\n",
    "\n",
    "        cluster_assign_ans = dataset['cluster_assign']\n",
    "        cluster_assign_ans_part = np.array(cluster_assign_ans)[participating_nodes]\n",
    "        cl_ct_ans = [np.sum(np.array(cluster_assign_ans_part) == p_i ) for p_i in range(p)]\n",
    "\n",
    "        res = {} # results\n",
    "        # res['losses'] = losses\n",
    "        # res['corrects'] = corrects\n",
    "        # res['cluster_assign'] = cluster_assign\n",
    "        res['loss'] = loss\n",
    "        res['acc'] = acc\n",
    "        # res['cl_acc'] = cl_acc\n",
    "        res['cl_ct'] = cl_ct\n",
    "        res['cl_ct_ans'] = cl_ct_ans\n",
    "        res['is_train'] = train\n",
    "\n",
    "        if train:\n",
    "            self.cluster_assign = cluster_assign\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "    def load_node_data(self, m_i, train=True):\n",
    "        if train:\n",
    "            dataset = self.dataset['train']\n",
    "        else:\n",
    "            dataset = self.dataset['test']\n",
    "\n",
    "        indices = dataset['data_indices'][m_i]\n",
    "\n",
    "        return self.load_data_by_index(indices, m_i, train)\n",
    "\n",
    "    def load_data_by_index(self, indices, m_i, train=True):\n",
    "\n",
    "        # transform\n",
    "        # maybe improve speed by tf.data.Dataset.apply?\n",
    "        # or just run pool map to this...\n",
    "        # maybe not needed\n",
    "\n",
    "        cfg = self.config\n",
    "\n",
    "        if train:\n",
    "            dataset = self.dataset['train']\n",
    "            transform_op = self.train_transform_op\n",
    "            # transform_op = self.test_transform_op\n",
    "        else:\n",
    "            dataset = self.dataset['test']\n",
    "            transform_op = self.test_transform_op\n",
    "\n",
    "\n",
    "        X_b = dataset['data_loader'][0][indices]\n",
    "        y_b = dataset['data_loader'][1][indices]\n",
    "\n",
    "        p_i = dataset['cluster_assign'][m_i]\n",
    "\n",
    "        if cfg['p'] == 4:\n",
    "            k = p_i\n",
    "        elif cfg['p'] == 2:\n",
    "            k = (p_i % 2) * 2\n",
    "        elif cfg['p'] == 1:\n",
    "            k = 0\n",
    "        else:\n",
    "            raise NotImplementedError(\"only p=1,2,4 supported\")\n",
    "\n",
    "        X_b2 = np.rot90(X_b, k=k, axes = (1,2)) # X_b: (bs, 32, 32, 3)\n",
    "\n",
    "        X_b3 = self.sess.run(transform_op, feed_dict = { self.x_tr_pl : X_b2 } )\n",
    "\n",
    "        return (X_b3, y_b)\n",
    "\n",
    "\n",
    "    # def save_checkpoint(self):\n",
    "    #     models_to_save = [model.state_dict() for model in self.models]\n",
    "    #     torch.save({'models':models_to_save}, self.checkpoint_fname)\n",
    "\n",
    "    #     pass\n",
    "\n",
    "IMAGE_SIZE = 28 # !!! was 24\n",
    "\n",
    "def train_transform(reshaped_image):\n",
    "    # copied from cifar10_input.py / distorted_input()\n",
    "\n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "\n",
    "    # Image processing for training the network. Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image = tf.random_crop(reshaped_image, [tf.shape(reshaped_image)[0], height, width, 3])\n",
    "    # tf shape gives dynamic shape\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # the order their operation.\n",
    "    distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                               max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "\n",
    "    return float_image\n",
    "\n",
    "def test_transform(reshaped_image):\n",
    "    # copied from cifar10_input.py / input()\n",
    "\n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "\n",
    "    # Image processing for evaluation.\n",
    "    # Crop the central [height, width] of the image.\n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n",
    "                                                         width, height)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(resized_image)\n",
    "\n",
    "    return float_image\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "\n",
    "def create_batches(pmt, batch_size):\n",
    "    batch_indices = []\n",
    "    ct = 0\n",
    "    for b_i in range(int(np.ceil( len(pmt) / batch_size))):\n",
    "        if ct + batch_size > len(pmt):\n",
    "            batch = pmt[ct : len(pmt)]\n",
    "            ct = len(pmt)\n",
    "        else:\n",
    "            batch = pmt[ct : ct + batch_size]\n",
    "            ct += batch_size\n",
    "        batch_indices.append(batch)\n",
    "\n",
    "    return batch_indices\n",
    "\n",
    "\n",
    "def our_data_creation():\n",
    "    # Load the dataset\n",
    "    import non_iiddata_generator_no_drifting as noniidgen\n",
    "    dataset_name = \"MNIST\"  # You can change this to \"FMNIST\", \"CIFAR10\", \"CIFAR100\", etc.\n",
    "    train_images, train_labels, test_images, test_labels = noniidgen.load_full_datasets(dataset_name)\n",
    "\n",
    "    # Define parameters for split_feature_skew\n",
    "    client_number = 10\n",
    "    set_rotation = True\n",
    "    rotations = 4\n",
    "    scaling_rotation_low = 0.1\n",
    "    scaling_rotation_high = 0.2\n",
    "    set_color = True\n",
    "    colors = 3\n",
    "    scaling_color_low = 0.1\n",
    "    scaling_color_high = 0.2\n",
    "    random_order = True\n",
    "\n",
    "    # Run split_feature_skew\n",
    "    clients_data = noniidgen.split_feature_skew(\n",
    "        train_features = train_images,\n",
    "        train_labels = train_labels,\n",
    "        test_features = test_images,\n",
    "        test_labels = test_labels,\n",
    "        client_number = client_number,\n",
    "        set_rotation = set_rotation,\n",
    "        rotations = rotations,\n",
    "        scaling_rotation_low = scaling_rotation_low,\n",
    "        scaling_rotation_high = scaling_rotation_high,\n",
    "        set_color = set_color,\n",
    "        colors = colors,\n",
    "        scaling_color_low = scaling_color_low,\n",
    "        scaling_color_high = scaling_color_high,\n",
    "        random_order = random_order\n",
    "    )\n",
    "    return clients_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'m': 10, 'm_test': 10, 'p': 2, 'n': 500, 'participation_rate': 1, 'num_epochs': 600, 'batch_size': 50, 'tau': 5, 'lr': 0.25, 'data_seed': 0, 'train_seed': 0, 'project_dir': 'output', 'dataset_dir': 'output', 'config_override': ''}\n"
     ]
    }
   ],
   "source": [
    "    config = {\n",
    "        \"m\" : 10,  \n",
    "        \"m_test\" : 10,\n",
    "        \"p\" : 2,\n",
    "        \"n\" : 500,\n",
    "\n",
    "        \"participation_rate\":1,\n",
    "\n",
    "        \"num_epochs\": 600,\n",
    "\n",
    "        \"batch_size\":50,\n",
    "        \"tau\":5,\n",
    "        \"lr\":0.25,\n",
    "\n",
    "        \"data_seed\":0,\n",
    "        \"train_seed\":0,\n",
    "        \"project_dir\":\"output\",\n",
    "        \"dataset_dir\":\"output\",\n",
    "        \"data_seed\":0,\n",
    "        \"train_seed\":0,\n",
    "        \"config_override\":\"\",\n",
    "    }\n",
    "    config['train_seed'] = config['data_seed']\n",
    "    print(\"config:\",config)\n",
    "\n",
    "    exp = TrainCIFARCluster(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 500)\n",
      "10\n",
      "(10, 500)\n",
      "10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable conv1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2356113/3135168685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2356113/2122109356.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_seed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2356113/2122109356.py\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_pl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_pl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# construct model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m    220\u001b[0m                                          \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                                          \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                                          wd=0.0)\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_variable_on_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biases'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py\u001b[0m in \u001b[0;36m_variable_with_weight_decay\u001b[0;34m(name, shape, stddev, wd)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n\u001b[0m\u001b[1;32m    143\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Clustered_FL/cfl_maggio/baselines/ifca/cifar/cifar10.py\u001b[0m in \u001b[0;36m_variable_on_cpu\u001b[0;34m(name, shape, initializer)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflags_use_fp16\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[0;32m~/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 868\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable conv1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/dario/anaconda3/envs/cfl_2/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "    exp.setup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfl_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
